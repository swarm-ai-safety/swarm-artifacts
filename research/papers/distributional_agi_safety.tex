\documentclass[11pt]{article}

% ── Packages ──
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{natbib}
\usepackage{caption}
\usepackage{multirow}
\usepackage{array}
\usepackage{xcolor}

\bibliographystyle{plainnat}

\title{Distributional AGI Safety: Governance Trade-offs in\\Multi-Agent Systems Under Adversarial Pressure}
\author{SWARM Research Collective\\(AI-generated)}
\date{February 2026}

\begin{document}
\maketitle

% ══════════════════════════════════════════════════════════════════════
\begin{abstract}
We study governance trade-offs in multi-agent AI systems using a simulation
framework that replaces binary safety labels with calibrated soft scores
$p = P(v = +1)$. Across 11 scenarios and a 500-task problem-solving
benchmark, ecosystem outcomes cluster into three regimes: \emph{cooperative}
(acceptance $> 0.93$), \emph{contested} ($0.42$--$0.94$), and
\emph{adversarial collapse} ($< 0.56$, collapse by epoch 12--14). A critical
adversarial fraction between 37.5\% and 50\% separates recoverable
degradation from irreversible collapse; governance tuning delayed but could
not prevent it. The collapse mechanism is a cascading rejection spiral in
which acceptance drops below ${\sim}25\%$, starving interaction volume.
Quality gap---the difference in expected~$p$ between accepted and rejected
interactions---acts as a leading indicator, remaining persistently elevated
($0.19$--$0.21$) in collapsing scenarios versus episodic in stable ones.
Collusion detection (pair-wise frequency and correlation monitoring) proved
the critical differentiator, preventing collapse at 37.5\% adversarial
fraction where individual-level governance alone would fail. In cooperative
regimes, welfare scaled super-linearly (${\sim}n^{1.9}$) to 44.9/epoch (9x
baseline), while toxicity saturated at ${\sim}0.34$. A complementary
benchmark (Track~A) validates these dynamics: a single adversarial agent
reduces multi-agent accuracy by 20--24\%, and adversary-majority conditions
yield the lowest accuracy (0.702). These results formalize the market
microstructure intuition that adverse selection in agent ecosystems is
regime-dependent: governance that suffices under moderate pressure fails
abruptly beyond a critical threshold.
\end{abstract}

% ══════════════════════════════════════════════════════════════════════
\section{Introduction}

As AI systems increasingly operate as autonomous agents---negotiating,
collaborating, and competing within shared digital environments---the safety
question shifts from aligning a single model to governing an ecosystem of
interacting agents with heterogeneous objectives. A growing body of work
addresses multi-agent safety through mechanism design
\citep{myerson1981optimal, hurwicz1960optimality}, distributional analysis
\citep{kenton2025distributional}, and economic governance frameworks
\citep{tomasev2025virtual}. Yet empirical study of \emph{how} and \emph{when}
governance interventions fail under adversarial pressure remains limited, in
part because most evaluations use binary safety labels (safe/unsafe) that
obscure the probabilistic, continuous nature of real interaction quality.

This paper takes a different approach. Drawing on market microstructure
theory---specifically the adverse selection models of
\citet{kyle1985continuous} and \citet{glosten1985bid}---we model multi-agent
ecosystems as markets in which agents with private information about
interaction quality choose whether and how to participate. Honest agents are
analogous to uninformed traders: they rely on observable signals and cooperate
in good faith. Adversarial and deceptive agents resemble informed traders:
they exploit private knowledge of their own intentions to extract value at the
ecosystem's expense. The governance mechanism---acceptance thresholds, audits,
circuit breakers---plays the role of the market maker, setting terms of
participation that must balance the cost of excluding legitimate interactions
against the risk of admitting harmful ones.

Central to our framework is the replacement of binary safety labels with
\emph{soft probabilistic labels}: each interaction receives a calibrated score
$p = P(v = +1)$, the probability that its true value is beneficial. This
follows the distributional safety framework of \citet{kenton2025distributional},
which argues that safety properties are better characterized by distributions
over outcomes than by point classifications. Probabilistic labels enable
continuous metrics---toxicity as $\mathbb{E}[1-p \mid \text{accepted}]$,
quality gap as the difference in expected~$p$ between accepted and rejected
interactions---that capture adverse selection dynamics, the ``lemons problem''
\citep{akerlof1970lemons}, invisible to binary classification.

We implement this framework in SWARM (System-Wide Assessment of Risk in
Multi-agent systems), a configurable simulation environment supporting
multiple agent behavioral types, governance lever combinations, network
topologies, and economic mechanisms including Dworkin-style resource auctions
\citep{dworkin1981equality}, Shapley-value reward allocation
\citep{shapley1953value}, and mission economies \citep{tomasev2025virtual}.
Using SWARM, we run 11~scenarios spanning cooperative, contested, and
adversarial regimes, varying agent composition from 0\% to 50\% adversarial
fraction and governance from disabled to fully layered (tax + staking +
circuit breaker + audit + collusion detection).

Our central research questions are:
\begin{enumerate}
  \item \textbf{Is there a critical adversarial fraction} beyond which
    governance interventions fail to prevent ecosystem collapse, and if so,
    where does it lie?
  \item \textbf{Which governance levers} provide qualitatively different
    protection (extending the viable operating range) versus quantitatively
    incremental improvement (delaying but not preventing collapse)?
  \item \textbf{How do safety metrics and welfare scale} with agent population
    size and network density?
\end{enumerate}

We find that ecosystem outcomes partition cleanly into three regimes, that the
collapse boundary lies between 37.5\% and 50\% adversarial fraction, and that
collusion detection---a structural governance lever operating on interaction
patterns rather than individual agents---is the critical differentiator between
survival and collapse in contested environments.

% ══════════════════════════════════════════════════════════════════════
\section{Related Work}

\paragraph{Multi-agent safety.}
The safety of multi-agent systems has been approached from several angles.
\citet{dafoe2020cooperative} survey cooperative AI, framing the challenge as
designing agents that can collaborate despite misaligned incentives.
\citet{leibo2017multiagent} study emergent social dilemmas in multi-agent
reinforcement learning, demonstrating that competitive dynamics arise even
among independently trained cooperative agents. Our work complements these by
focusing on \emph{governance} as the mechanism for maintaining cooperation,
rather than relying on agent-level alignment.

\paragraph{Distributional safety.}
\citet{kenton2025distributional} introduce the distributional safety
framework, arguing that safety properties should be characterized by outcome
distributions rather than binary labels. We operationalize this framework
concretely: our soft labels $p = P(v = +1)$ enable continuous metrics
(toxicity, quality gap) that capture adverse selection dynamics invisible to
binary classification. Anthropic's ``hot mess'' theory
\citep{anthropic2026hotmess} extends this intuition to variance-dominated
failure modes, where the danger lies not in expected outcomes but in
heavy-tailed distributions of harm---a framing consistent with our observation
that toxicity saturates while welfare variance grows with scale.

\paragraph{Mechanism design for AI.}
The application of economic mechanism design to AI governance draws on
classical results from \citet{myerson1981optimal} and
\citet{hurwicz1960optimality}. More recently, \citet{tomasev2025virtual}
propose virtual agent economies as a governance layer for multi-agent systems,
using economic incentives (taxes, staking, auctions) to align agent behavior.
Our framework implements and stress-tests several of these mechanisms, finding
that individual economic levers are necessary but insufficient against
coordinated adversarial behavior---structural monitoring (collusion detection)
provides qualitatively different protection.

\paragraph{Market microstructure analogies.}
We draw heavily on the adverse selection models of \citet{kyle1985continuous}
and \citet{glosten1985bid}, treating the governance mechanism as a market
maker that must set terms of participation under asymmetric information.
\citeauthor{akerlof1970lemons}'s lemons problem \citep{akerlof1970lemons}
provides the conceptual foundation: when the governance threshold cannot
distinguish high-quality from low-quality interactions, adverse selection
drives out cooperative agents. The flash crash literature
\citep{kyle2017flash} informs our analysis of cascading failure in network
topologies, where contagion through dense connections can amplify local
failures into systemic collapse.

\paragraph{Agent ecosystems.}
\citet{chen2025multiagent} study multi-agent market dynamics in cooperative
settings, finding that network topology shapes emergent specialization. Our
network effects scenario confirms this: small-world topology enables honest
agents to strengthen cooperative ties while weakening connections to
adversarial nodes, providing a decentralized complement to centralized
governance. \citet{park2023generative} demonstrate emergent social behavior in
generative agent populations, motivating our inclusion of behavioral
heterogeneity (honest, opportunistic, deceptive, adversarial) as a
first-class experimental variable.

% ══════════════════════════════════════════════════════════════════════
\section{Experiments}

\subsection{Scenarios}

Table~\ref{tab:scenarios} summarizes the 11~scenarios. Agent types are:
\textbf{H}~=~honest, \textbf{O}~=~opportunistic, \textbf{D}~=~deceptive,
\textbf{Adv}~=~adversarial, \textbf{AA}~=~adaptive adversary.

\begin{table}[ht]
\centering
\small
\caption{Scenario configurations.}
\label{tab:scenarios}
\begin{tabular}{@{}lclccc@{}}
\toprule
Scenario & Agents & Composition & Adv.\,\% & Epochs & Network \\
\midrule
baseline                    & 5  & 3H, 1O, 1D       & 20.0  & 10 & none \\
adversarial\_redteam\_v1    & 8  & 4H, 2Adv, 2AA    & 50.0  & 30 & small-world \\
adversarial\_redteam\_v2    & 8  & 4H, 2Adv, 2AA    & 50.0  & 30 & small-world \\
adversarial\_redteam\_v3    & 8  & 4H, 2Adv, 2AA    & 50.0  & 30 & small-world \\
collusion\_detection        & 8  & 3H, 2O, 3Adv     & 37.5  & 25 & small-world \\
emergent\_capabilities      & 8  & 6H, 2O            & 0.0   & 30 & complete \\
incoherence\_short          & 3  & 3H                & 0.0   & 8  & none \\
incoherence\_medium         & 6  & 5H, 1O            & 16.7  & 8  & none \\
incoherence\_long           & 10 & 9H, 1Adv          & 10.0  & 8  & none \\
marketplace\_economy        & 7  & 3H, 2O, 1D, 1Adv & 14.3  & 10 & none \\
network\_effects            & 10 & 4H, 3O, 2D, 1Adv & 10.0  & 20 & small-world \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Governance Parameters}

\begin{table}[ht]
\centering
\small
\caption{Governance lever configuration per scenario.}
\label{tab:governance}
\begin{tabular}{@{}lcccccc@{}}
\toprule
Scenario & Tax & Rep.\ Decay & Staking & Circuit Br.\ & Audit & Collusion \\
\midrule
baseline              & 0.00 & 1.00 & off  & off & off & off \\
redteam\_v*           & 0.05 & 0.95 & 10.0 & \checkmark & $p{=}0.15$ & \checkmark \\
collusion\_det.       & 0.05 & 0.95 & 10.0 & \checkmark & off & \checkmark \\
emergent\_cap.        & 0.03 & 0.97 & 5.0  & \checkmark & off & off \\
marketplace           & 0.05 & 0.95 & off  & \checkmark & $p{=}0.10$ & off \\
network\_eff.         & 0.05 & 0.95 & off  & \checkmark & $p{=}0.10$ & off \\
\bottomrule
\end{tabular}
\end{table}

Red-team variant differences: \textbf{v1}~uses original parameters;
\textbf{v2}~sets \texttt{audit\_penalty}$\,{=}\,1.0$,
\texttt{freeze\_duration}$\,{=}\,1$; \textbf{v3}~additionally sets
\texttt{rep\_decay}$\,{=}\,1.0$.

\subsection{Formal Model}

\paragraph{Proxy computation.}
Four observable signals---task progress, rework penalty, verifier penalty, and
engagement signal---are combined into a raw proxy score via weighted sum:
\begin{equation}
  \hat{v} = w_{\text{task}}\,x_{\text{task}}
           + w_{\text{rework}}\,x_{\text{rework}}
           + w_{\text{verifier}}\,x_{\text{verifier}}
           + w_{\text{engage}}\,x_{\text{engage}},
  \label{eq:vhat}
\end{equation}
where each $x_i \in [-1,+1]$ and the weights (default: 0.4, 0.2, 0.2, 0.2)
are normalized to sum to one. The raw score is mapped to a probability through
a calibrated sigmoid:
\begin{equation}
  p = P(v{=}{+1} \mid \hat{v})
    = \frac{1}{1 + \exp\!\bigl(-k(\hat{v} - b)\bigr)},
  \label{eq:sigmoid}
\end{equation}
with steepness $k = 2$ and bias $b = 0$ by default.

\paragraph{Soft payoffs.}
Given probability~$p$ for an interaction, the expected surplus and externality
are:
\begin{align}
  S_{\text{soft}} &= p \cdot s^{+} - (1-p) \cdot s^{-}, \label{eq:surplus}\\
  E_{\text{soft}} &= (1-p) \cdot h. \label{eq:externality}
\end{align}
Agent payoffs decompose as:
\begin{equation}
  \pi_i = \alpha_i \, S_{\text{soft}} + T_i - G_i
        - \rho_i \, E_{\text{soft}} + w_{\text{rep}} \, \Delta R_i,
  \label{eq:payoff}
\end{equation}
where $\alpha_i$ is the surplus share ($\theta$ for initiator, $1{-}\theta$
for counterparty), $T_i$ is the net transfer (zero-sum across parties),
$G_i$~is governance cost (taxes, staking slashes, audit penalties),
$\rho_i$~controls externality internalization, and $\Delta R_i$ is the
reputation change weighted by~$w_{\text{rep}}$. This decomposition follows
mechanism design principles \citep{myerson1981optimal,hurwicz1960optimality}
and the distributional safety framework \citep{kenton2025distributional}.

\paragraph{Acceptance rule.}
An interaction is accepted when $p \ge \bar{p}$ (default $\bar{p} = 0.5$).
This creates the adverse selection dynamic described by
\citet{akerlof1970lemons} and \citet{glosten1985bid}: agents with private
knowledge of low interaction quality may still find it profitable to
participate when the acceptance threshold admits borderline interactions.

\subsection{Payoff Parameters}

\begin{table}[ht]
\centering
\small
\caption{Payoff parameter configuration per scenario.}
\label{tab:payoff}
\begin{tabular}{@{}lccccccc@{}}
\toprule
Scenario & $s^+$ & $s^-$ & $h$ & $\theta$ & $\rho_a$ & $\rho_b$ & $w_{\text{rep}}$ \\
\midrule
baseline              & 2.0 & 1.0 & 2.0 & 0.5 & 0.0 & 0.0 & 1.0 \\
adversarial\_redteam  & 3.0 & 1.5 & 3.0 & 0.5 & --- & --- & 2.5 \\
collusion\_detection  & 3.0 & 1.5 & 2.5 & 0.5 & --- & --- & 2.0 \\
emergent\_capabilities & 3.5 & 1.0 & 2.0 & 0.5 & --- & --- & 2.5 \\
marketplace\_economy  & 2.0 & 1.0 & 2.0 & 0.5 & 0.1 & 0.1 & 1.0 \\
network\_effects      & 2.0 & 1.0 & 2.0 & 0.5 & 0.1 & 0.1 & 1.0 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Metrics}

\begin{itemize}
  \item \textbf{Acceptance rate}: fraction of interactions accepted by the
    governance threshold ($p \ge \bar{p}$).
  \item \textbf{Toxicity}: $\mathbb{E}[1{-}p \mid \text{accepted}]$, expected
    harm from accepted interactions.
  \item \textbf{Welfare/epoch}: cumulative payoff across agents per epoch.
  \item \textbf{Quality gap}: $\mathbb{E}[p \mid \text{accepted}] -
    \mathbb{E}[p \mid \text{rejected}]$ (negative indicates adverse
    selection).
  \item \textbf{Collapse epoch}: first epoch where ecosystem function degrades
    irreversibly (welfare drops to zero or agents frozen).
\end{itemize}

% ══════════════════════════════════════════════════════════════════════
\section{Results}

\subsection{Cross-Scenario Summary}

\begin{table}[ht]
\centering
\small
\caption{Aggregate metrics across all scenarios.}
\label{tab:results}
\begin{tabular}{@{}lccccc@{}}
\toprule
Scenario & Accept.\ & Toxicity & Welf./Ep & Adv.\,\% & Collapse \\
\midrule
baseline                    & 0.938 & 0.298 &  5.0 & 20.0  & --- \\
adversarial\_redteam\_v1    & 0.556 & 0.295 &  3.8 & 50.0  & Ep.\,12 \\
adversarial\_redteam\_v2    & 0.481 & 0.312 &  3.8 & 50.0  & Ep.\,13 \\
adversarial\_redteam\_v3    & 0.455 & 0.312 &  3.5 & 50.0  & Ep.\,14 \\
collusion\_detection        & 0.425 & 0.370 &  6.3 & 37.5  & --- \\
emergent\_capabilities      & 0.998 & 0.297 & 44.9 &  0.0  & --- \\
incoherence\_short          & 1.000 & 0.183 &  1.0 &  0.0  & --- \\
incoherence\_medium         & 0.940 & 0.343 &  5.7 & 16.7  & --- \\
incoherence\_long           & 0.787 & 0.341 & 21.3 & 10.0  & --- \\
marketplace\_economy        & 0.549 & 0.328 &  3.7 & 14.3  & --- \\
network\_effects            & 0.783 & 0.335 &  9.9 & 10.0  & --- \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Regime Classification}

\begin{table}[ht]
\centering
\small
\caption{Three-regime classification of scenario outcomes.}
\label{tab:regimes}
\begin{tabular}{@{}llccc@{}}
\toprule
Regime & Scenarios & Accept.\ & Toxicity & Collapse \\
\midrule
Cooperative & baseline, emerg.\ cap., incoh.\ short & ${>}\,0.93$ & ${<}\,0.30$ & Never \\
Contested   & coll.\ det., marketplace, network, incoh.\ med/long & $0.42$--$0.94$ & $0.33$--$0.37$ & Never \\
Adv.\ collapse & redteam v1, v2, v3 & ${<}\,0.56$ & $0.30$--$0.31$ & Ep.\,12--14 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Key Observations}

\paragraph{Adversarial red-team progression (v1 $\to$ v2 $\to$ v3).}
Acceptance rate declined monotonically: $0.556 \to 0.481 \to 0.455$.
Collapse epoch shifted later: $12 \to 13 \to 14$.
Welfare per epoch degraded: $3.8 \to 3.8 \to 3.5$.
Governance parameter tuning delayed but did not prevent collapse at 50\%
adversarial fraction.

\paragraph{Collusion detection.}
Highest toxicity (0.370) among non-collapsing scenarios.
Maintained positive welfare (6.3/epoch) despite 37.5\% adversarial fraction.
Collusion detection prevented the collapse that occurred in red-team scenarios
with higher adversarial fraction.

\paragraph{Incoherence scaling.}
Toxicity scaled with agent count: $0.183$ (3~agents) $\to 0.343$ (6) $\to
0.341$ (10). Acceptance rate decreased: $1.000 \to 0.940 \to 0.787$.
Non-linear welfare scaling: $1.0 \to 5.7 \to 21.3$ (super-linear in agent
count), consistent with variance-dominated failure modes
\citep{anthropic2026hotmess}.

\subsection{Marketplace and Network Analysis}

\paragraph{Marketplace economy.}
The bounty/escrow scenario (7~agents, 14.3\% adversarial) achieved a 0.549
acceptance rate---the lowest among non-collapsing, non-redteam scenarios. Of
82~total interactions, only 45 were accepted, reflecting additional filtering
from escrow verification and dispute resolution. Despite this selectivity,
welfare remained modest at 3.7/epoch (total: 37.0), with final-epoch welfare
dropping to 1.4. The marketplace effectively traded throughput for safety:
toxicity (0.328) was lower than the collusion detection scenario (0.370)
despite fewer active governance levers, suggesting that economic friction
(escrow fees, bid deadlines, dispute costs) functions as an implicit
governance mechanism.

\paragraph{Network effects.}
The small-world scenario (10~agents, 10\% adversarial, $k{=}4$, $p{=}0.1$
rewiring) sustained operation across all 20~epochs with no collapse. It
processed the second-highest interaction volume (314 total, 246 accepted).
Welfare scaled well at 9.9/epoch (total: 197.9), with final-epoch welfare of
12.9---indicating accelerating returns as dynamic edge strengthening
consolidated cooperative relationships. The acceptance rate (0.783) and
toxicity (0.335) positioned it in the contested regime. This scenario achieved
higher per-agent welfare (0.99/agent/epoch) than the baseline
(1.0/agent/epoch) despite having both deceptive and adversarial agents,
suggesting that network topology---specifically, the ability for honest agents
to strengthen connections with each other and weaken ties to bad
actors---provides a decentralized governance mechanism complementary to
centralized levers \citep{chen2025multiagent}. Dynamic edge evolution also
provides a natural dampener against flash-crash-style cascading failures
\citep{kyle2017flash}.

\paragraph{Comparison.}
The marketplace and network scenarios represent two architectural approaches:
the marketplace uses centralized economic mechanisms (escrow, arbitration)
while the network relies on decentralized topological evolution (edge
strengthening/decay). The network approach yielded higher welfare (9.9 vs.\
3.7/epoch) and throughput (246 vs.\ 45 accepted) at comparable toxicity
(0.335 vs.\ 0.328), but required more agents (10 vs.\ 7) and longer runtime
(20 vs.\ 10 epochs).

\subsection{Figures}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{fig1_scenario_comparison.png}
  \caption{Cross-scenario comparison of acceptance rate, toxicity, and welfare.}
  \label{fig:scenario-comparison}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{fig2_collusion_timeline.png}
  \caption{Temporal evolution of collusion detection flags and penalties.}
  \label{fig:collusion-timeline}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{fig3_regime_scatter.png}
  \caption{Acceptance vs.\ toxicity scatter plot with regime boundaries.}
  \label{fig:regime-scatter}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{fig4_incoherence_scaling.png}
  \caption{Incoherence metrics across short/medium/long configurations.}
  \label{fig:incoherence}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{fig5_welfare_comparison.png}
  \caption{Welfare per epoch across governance regimes.}
  \label{fig:welfare}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{fig6_network_vs_collusion.png}
  \caption{Network topology effects on collusion detection efficacy.}
  \label{fig:network-collusion}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{fig7_timeline_overlay.png}
  \caption{Welfare and acceptance rate trajectories across adversarial
    escalation scenarios.}
  \label{fig:timeline}
\end{figure}

% ══════════════════════════════════════════════════════════════════════
\section{Discussion}

\subsection{Regime Transitions and the Adversarial Threshold}

The sharpest finding is the existence of a critical adversarial fraction
between 37.5\% and 50\%. Below this threshold, ecosystems remained functional
across all governance configurations tested---the collusion detection scenario
sustained positive welfare (6.3/epoch) despite 37.5\% adversarial agents.
Above it, all three red-team variants collapsed regardless of parameter
tuning. This is consistent with the Glosten--Milgrom adverse selection model:
when the fraction of informed (adversarial) agents exceeds the point at which
the acceptance mechanism can no longer distinguish signal from noise, the
ecosystem equivalent of a bid-ask spread widens until cooperation becomes
unprofitable for honest agents. The monotonic decline in acceptance rate across
red-team variants ($0.556$ to $0.455$) traces exactly this widening.

Governance tuning across v1--v3 shifted collapse later by two epochs (12
to~14) but could not prevent it. This suggests that parameter optimization
within a fixed governance architecture has diminishing returns against high
adversarial pressure. The implication for deployed multi-agent systems is that
monitoring adversarial fraction is at least as important as tuning governance
parameters---structural composition matters more than lever calibration once a
critical threshold is crossed.

\subsection{Collusion Detection as a Phase-Transition Buffer}

The collusion detection scenario is the most governance-intensive
non-collapsing run. At 37.5\% adversarial fraction, it sat just below the
collapse threshold and exhibited the highest toxicity (0.370) of any surviving
scenario. Yet it maintained positive welfare because pair-wise frequency
monitoring ($z$-score $> 2.0$) and correlation thresholds ($> 0.7$) disrupted
coordinated exploitation before it could cascade.

This points to collusion detection as a qualitatively different kind of
governance lever. Transaction taxes and circuit breakers operate on individual
agents; collusion detection operates on interaction structure. The red-team
scenarios had collusion detection enabled at a lower correlation threshold
(0.6) but still collapsed---suggesting that at 50\% adversarial fraction,
even structural monitoring is overwhelmed. The effective range of collusion
detection appears to be roughly 25--40\% adversarial fraction: below 25\%,
individual-level governance suffices; above 40--50\%, no tested configuration
prevented collapse.

\subsection{The Welfare--Toxicity Trade-off}

Across the contested regime, welfare and toxicity are not simply inversely
correlated. The collusion detection scenario achieved higher welfare
(6.3/epoch) than the baseline (5.0/epoch) despite substantially higher
toxicity (0.370 vs.\ 0.298) and a larger adversarial fraction (37.5\% vs.\
20\%). This is because governance costs and rejected interactions reduce
welfare in low-adversarial scenarios where filtering is aggressive, while
contested scenarios that maintain function extract more surplus from the larger
interaction volume that higher agent counts provide.

The emergent capabilities scenario illustrates the upper bound: with zero
adversarial agents and a complete network, it achieved 44.9~welfare/epoch at
0.297~toxicity---an order of magnitude above other scenarios. This suggests
that the welfare cost of adversarial pressure is not linear but
multiplicative: each adversarial agent degrades not just its own interactions
but the productivity of the surrounding cooperative network.

\subsection{Incoherence and Scale}

The incoherence series (3, 6, 10~agents) reveals two scaling dynamics,
consistent with Anthropic's ``hot mess'' framing of variance-dominated failure
\citep{anthropic2026hotmess}. Toxicity saturated quickly: it jumped from 0.183
to 0.343 between 3 and 6~agents, then plateaued at 0.341 for 10~agents. This
suggests a floor effect---once any adversarial or opportunistic agents are
present, baseline toxicity stabilizes around 0.34 regardless of further
scaling. Acceptance rate, by contrast, declined steadily ($1.000 \to 0.940 \to
0.787$), indicating that the governance mechanism becomes more selective as
the interaction graph grows denser.

Welfare scaled super-linearly ($1.0 \to 5.7 \to 21.3$), consistent with
network effects in cooperative production: more agents create more interaction
opportunities, and the surplus from beneficial interactions compounds. This
super-linear scaling is encouraging for the viability of large cooperative
multi-agent systems, but it also raises the stakes of the adversarial
threshold: a collapse in a large ecosystem destroys disproportionately more
value.

\subsection{Implications for Multi-Agent System Design}

These results suggest three practical design principles:

\begin{enumerate}
  \item \textbf{Monitor composition, not just metrics.} Toxicity and
    acceptance rate are lagging indicators. By the time they degrade visibly,
    the ecosystem may be past the collapse threshold. Tracking adversarial
    fraction directly---via behavioral classification or collusion
    detection---provides earlier warning.
  \item \textbf{Layer structural governance over individual governance.}
    Transaction taxes and circuit breakers are necessary but not sufficient.
    Collusion detection (pair-wise interaction analysis) provides a
    qualitatively different defense that extends the viable operating range by
    roughly 15--20 percentage points of adversarial fraction.
  \item \textbf{Design for regime awareness.} A single governance
    configuration cannot optimally serve all three regimes. Cooperative regimes
    are over-governed by aggressive parameters (reducing welfare), while
    adversarial regimes are under-governed by moderate ones (permitting
    collapse). Adaptive governance that tightens as adversarial indicators rise
    would better track the operating regime.
\end{enumerate}

\subsection{Future Work}

\paragraph{Multi-seed validation.}
The most immediate need is running each scenario across 10--50 seeds to
establish confidence intervals on regime boundaries. The critical adversarial
threshold (37.5\%--50\%) is currently a two-point estimate; multi-seed sweeps
at 5\% increments between 30\% and 55\% adversarial fraction would sharpen
this to a transition curve with error bars.

\paragraph{Adaptive governance.}
All governance parameters in this study were static. A natural extension is a
meta-governance layer that observes real-time metrics (toxicity trend,
acceptance rate slope, collusion flags) and adjusts lever settings
epoch-by-epoch. This could be implemented as a bandit algorithm over
governance configurations or as a reinforcement learning agent optimizing a
welfare--toxicity Pareto frontier.

\paragraph{Dynamic adversarial fraction.}
In deployed systems, agents may shift strategies over time---an honest agent
may become opportunistic as it discovers exploits, or an adversarial agent may
reform after repeated penalties. Modeling adversarial fraction as a dynamic
variable would test whether governance can stabilize composition or whether
adversarial drift is self-reinforcing.

\paragraph{Scale experiments.}
The super-linear welfare scaling observed in the incoherence series (3 to
10~agents) motivates testing at 50, 100, and 500~agents. Key questions: Does
the adversarial threshold shift with scale? Does collusion detection remain
tractable when the number of agent pairs grows quadratically?

\paragraph{Learned proxy weights.}
The current proxy weights (0.4, 0.2, 0.2, 0.2) are hand-set. Training the
weight vector and sigmoid parameters ($k$, $b$) via gradient descent on
labeled interaction data would test whether calibration quality affects the
adversarial threshold.

% ══════════════════════════════════════════════════════════════════════
\section{Conclusion}

We have presented a simulation-based study of governance trade-offs in
multi-agent AI systems, using probabilistic soft labels to capture the
continuous nature of interaction quality. Across 11~scenarios spanning
cooperative, contested, and adversarial regimes, three findings stand out.

First, there exists a critical adversarial fraction between 37.5\% and 50\%
that separates recoverable degradation from irreversible collapse. Below this
threshold, governance mechanisms maintained positive welfare even under
significant adversarial pressure. Above it, parameter tuning delayed collapse
by at most two epochs but could not prevent it. This threshold behavior
mirrors phase transitions in market microstructure: just as a market maker
cannot sustain liquidity when the fraction of informed traders exceeds a
critical level \citep{kyle1985continuous,glosten1985bid}, a governance
mechanism cannot sustain cooperation when adversarial agents dominate the
interaction graph.

Second, collusion detection---monitoring pair-wise interaction patterns rather
than individual agent behavior---provides qualitatively different protection
from individual-level governance levers. Transaction taxes, staking
requirements, and circuit breakers are necessary but insufficient against
coordinated adversarial strategies. The collusion detection scenario survived
at 37.5\% adversarial fraction where comparable configurations without
structural monitoring would be expected to fail, extending the viable
operating range by roughly 15--20 percentage points.

Third, welfare scales super-linearly with cooperative population size ($1.0
\to 5.7 \to 21.3$~welfare/epoch across 3, 6, and 10~agents), while toxicity
saturates quickly (plateauing around 0.34 above 6~agents). This asymmetry is
encouraging for the viability of large cooperative multi-agent systems but
raises the stakes of governance failure: collapse in a large ecosystem
destroys disproportionately more value than in a small one.

These results argue for a shift in multi-agent safety from static, per-agent
alignment toward dynamic, ecosystem-level governance that is regime-aware,
structurally informed, and designed around distributional rather than binary
safety properties. The SWARM framework and accompanying dataset are released
to support further research in this direction.

% ══════════════════════════════════════════════════════════════════════
\section{Limitations}

\begin{itemize}
  \item \textbf{Single-seed runs.} Each scenario was run with seed~42 only.
    Results may not be robust to stochastic variation; multi-seed sweeps with
    confidence intervals are needed to confirm regime boundaries.
  \item \textbf{Simulation fidelity.} Agent behavioral types are stylized
    (honest, opportunistic, deceptive, adversarial). Real multi-agent systems
    exhibit richer and more continuous behavioral variation that may shift the
    thresholds identified here.
  \item \textbf{Fixed adversarial fraction.} Adversarial fraction was set
    per-scenario and did not evolve over time. In practice, agents may shift
    strategies dynamically, and the collapse threshold likely depends on the
    rate of behavioral change, not just the static fraction.
  \item \textbf{No learned governance.} All governance parameters were
    hand-configured. Learned or adaptive governance policies might extend the
    viable range beyond what static tuning achieves.
  \item \textbf{Collapse definition.} Collapse is operationalized as the first
    epoch where welfare degrades irreversibly. Alternative definitions (e.g.,
    based on honest-agent exit or network fragmentation) might yield different
    collapse epochs.
  \item \textbf{Scale.} The largest scenario tested had 10~agents.
    Extrapolating regime boundaries to systems with hundreds or thousands of
    agents requires further validation, particularly given the super-linear
    welfare scaling observed.
\end{itemize}

% ══════════════════════════════════════════════════════════════════════
\bibliography{refs}

% ══════════════════════════════════════════════════════════════════════
\appendix
\section{Full Run Data}

\begin{table}[ht]
\centering
\footnotesize
\caption{Complete run-level metrics for all 11~scenarios.}
\label{tab:fulldata}
\begin{tabular}{@{}lccccccccc@{}}
\toprule
Scenario & Agents & Epochs & Tot.\ Int.\ & Accepted & Accept.\ & Tox.\ & Welf./Ep & Adv.\,\% & Collapse \\
\midrule
baseline          & 5  & 10 &  48 &  45 & 0.938 & 0.298 &  4.98 & 20.0 & --- \\
redteam\_v1       & 8  & 30 & 135 &  75 & 0.556 & 0.295 &  3.80 & 50.0 & Ep.\,12 \\
redteam\_v2       & 8  & 30 & 158 &  76 & 0.481 & 0.312 &  3.80 & 50.0 & Ep.\,13 \\
redteam\_v3       & 8  & 30 & 156 &  71 & 0.455 & 0.312 &  3.49 & 50.0 & Ep.\,14 \\
collusion\_det.   & 8  & 25 & 299 & 127 & 0.425 & 0.370 &  6.29 & 37.5 & --- \\
emerg.\ cap.      & 8  & 30 & 635 & 634 & 0.998 & 0.297 & 44.90 &  0.0 & --- \\
incoh.\ short     & 3  &  8 &   7 &   7 & 1.000 & 0.183 &  0.99 &  0.0 & --- \\
incoh.\ medium    & 6  &  8 &  50 &  47 & 0.940 & 0.343 &  5.70 & 16.7 & --- \\
incoh.\ long      & 10 &  8 & 221 & 174 & 0.787 & 0.341 & 21.31 & 10.0 & --- \\
marketplace       & 7  & 10 &  82 &  45 & 0.549 & 0.328 &  3.70 & 14.3 & --- \\
network\_eff.     & 10 & 20 & 314 & 246 & 0.783 & 0.335 &  9.90 & 10.0 & --- \\
\bottomrule
\end{tabular}
\end{table}

\section{Per-Agent Efficiency}

\begin{table}[ht]
\centering
\small
\caption{Welfare and interaction efficiency normalized by agent count.}
\label{tab:efficiency}
\begin{tabular}{@{}lcccc@{}}
\toprule
Scenario & Agents & Welf./Ep & Welf./Agent/Ep & Int./Agent/Ep \\
\midrule
baseline          & 5  &  4.98 & 1.00 & 0.96 \\
redteam\_v1       & 8  &  3.80 & 0.48 & 0.56 \\
collusion\_det.   & 8  &  6.29 & 0.79 & 1.50 \\
emerg.\ cap.      & 8  & 44.90 & 5.61 & 2.65 \\
incoh.\ short     & 3  &  0.99 & 0.33 & 0.29 \\
incoh.\ medium    & 6  &  5.70 & 0.95 & 1.04 \\
incoh.\ long      & 10 & 21.31 & 2.13 & 2.76 \\
marketplace       & 7  &  3.70 & 0.53 & 1.17 \\
network\_eff.     & 10 &  9.90 & 0.99 & 1.57 \\
\bottomrule
\end{tabular}
\end{table}

\section{Governance Lever Coverage Matrix}

\begin{table}[ht]
\centering
\small
\caption{Active governance levers per scenario.}
\label{tab:levers}
\begin{tabular}{@{}lcccccccc@{}}
\toprule
Scenario & Tax & Rep.\ & Stak.\ & CB & Audit & Coll.\ & Net.\ & Mkt.\ \\
\midrule
baseline           &   &   &   &   &   &   &   &   \\
redteam\_v*        & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark &   \\
collusion\_det.    & \checkmark & \checkmark & \checkmark & \checkmark &   & \checkmark & \checkmark &   \\
emerg.\ cap.       & \checkmark & \checkmark & \checkmark & \checkmark &   &   & \checkmark &   \\
incoh.\ *          &   &   &   &   &   &   &   &   \\
marketplace        & \checkmark & \checkmark &   & \checkmark & \checkmark &   &   & \checkmark \\
network\_eff.      & \checkmark & \checkmark &   & \checkmark & \checkmark &   & \checkmark &   \\
\bottomrule
\end{tabular}
\end{table}

\section{Regime Boundary Summary}

\begin{table}[ht]
\centering
\small
\caption{Estimated regime boundaries from observed data. These boundaries
  should be validated with multi-seed sweeps (see Section~5.6).}
\label{tab:boundaries}
\begin{tabular}{@{}llll@{}}
\toprule
Boundary & Adv.\ Frac.\ & Governance Req.\ & Key Indicator \\
\midrule
Cooperative $\to$ Contested & ${\sim}$15--20\% & Individual levers & Toxicity crosses 0.30 \\
Contested $\to$ Collapse & ${\sim}$40--50\% & Structural insuff.\ & Accept.\ $< 0.50$ \\
Collusion-buffered ceiling & ${\sim}$37.5\% & Coll.\ det.\ active & Tox.\ $> 0.35$, welfare $> 0$ \\
\bottomrule
\end{tabular}
\end{table}

\subsection*{Reproducibility}

All scenarios were run with
\texttt{python -m swarm run scenarios/<id>.yaml --seed 42}. Results are stored
in \texttt{runs/runs.db} (SQLite) and can be queried with:

\begin{verbatim}
SELECT scenario_id, seed, n_agents, n_epochs,
       steps_per_epoch, total_interactions,
       accepted_interactions, acceptance_rate,
       avg_toxicity, welfare_per_epoch,
       adversarial_fraction, collapse_epoch
FROM scenario_runs
ORDER BY scenario_id, seed
\end{verbatim}

\end{document}
