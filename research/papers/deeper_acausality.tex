% SWARM Paper â€” deeper_acausality
% Generated from docs/papers/deeper_acausality.md

\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{array}
\usepackage{longtable}
\usepackage{float}
\usepackage{enumitem}
\usepackage{verbatim}

\title{Deeper Acausality Does Not Produce Deeper Cooperation:\\A Multi-Agent Simulation Study}
\author{SWARM Research Collective}
\date{February 2026}

\begin{document}
\maketitle

\begin{abstract}
We extend Logical Decision Theory (LDT) agents in the SWARM simulation framework with two new acausal reasoning mechanisms --- transitive twin graphs (depth~4) and Monte Carlo counterfactual sampling (depth~5) --- and test whether deeper acausal reasoning improves cooperation outcomes in mixed-motive multi-agent populations. Across 200 simulation runs spanning 5 acausality depths, 3 population scales (11, 25, and 50 agents), and up to 20 random seeds per condition, we find that \textbf{deeper reasoning does not monotonically improve cooperation}. Recursive equilibrium (depth~3) achieves the highest welfare (+3.1\% over depth~1) and LDT payoff (+7.1\% over depth~1) at small scale ($N=11$), but all depth advantages vanish as population size increases. At $N=50$, depths 1--5 produce statistically indistinguishable welfare (722.8 vs 712.1, $p > 0.05$) and toxicity (0.271 across all depths). These results suggest that the computational overhead of deeper acausal reasoning is not justified at scale, and that simpler reasoning mechanisms are sufficient when populations are large enough for statistical regularities to dominate individual decision quality.
\end{abstract}

\section{Introduction}

Logical Decision Theory (LDT) and its variants --- Timeless Decision Theory (TDT), Functional Decision Theory (FDT), and Updateless Decision Theory (UDT) --- propose that rational agents should reason about \textit{logical counterfactuals} rather than causal or evidential correlations when making decisions (Soares \& Fallenstein, 2017; Yudkowsky \& Soares, 2018). A central claim is that agents employing deeper acausal reasoning can achieve better cooperation outcomes, particularly in scenarios involving prediction, logical correlation, and subjunctive dependence.

We test this claim empirically by implementing five levels of acausal reasoning depth in the SWARM soft-label simulation framework:

\begin{itemize}
  \item \textbf{Depth 1}: Behavioral twin detection via cosine similarity
  \item \textbf{Depth 2}: Policy introspection --- inferring counterparty decision parameters
  \item \textbf{Depth 3}: Recursive equilibrium --- iterated best-response convergence
  \item \textbf{Depth 4}: Transitive twin graphs --- BFS-based discovery of indirect logical twins with exponential decay
  \item \textbf{Depth 5}: Monte Carlo counterfactual sampling --- Gaussian perturbation of counterparty signals averaged over $N$ samples
\end{itemize}

Depths 1--3 were established in prior work on this framework. Depths 4--5 are new contributions of this paper, designed to test whether extending the acausal reasoning chain beyond recursive equilibrium yields further cooperation gains.

Our central research question is: \textbf{Does deeper acausal reasoning produce deeper cooperation, and if so, does the effect persist as population size scales?}

\section{Methods}

\subsection{Agent Architecture}

All LDT agents share a common base architecture with configurable acausality depth. Each agent maintains:

\begin{itemize}
  \item A \textbf{behavioral profile} for each counterparty: a list of (accepted, $p$) tuples recording interaction outcomes
  \item A \textbf{twin score} cache: cosine similarity between own and counterparty behavior vectors
  \item \textbf{Policy inference} models (depth $\geq 2$): estimated cooperation prior, similarity threshold, welfare weight, and updateless commitment for each counterparty
  \item A \textbf{recursive equilibrium} solver (depth $\geq 3$): iterated best-response until convergence
  \item A \textbf{twin graph} (depth $\geq 4$): agent-local adjacency dict with edges weighted by behavioral similarity
  \item A \textbf{Monte Carlo RNG} (depth $\geq 5$): seeded from the agent's base RNG for deterministic sampling
\end{itemize}

Key parameters held constant across all conditions:

\begin{table}[H]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
cooperation\_prior & 0.65 \\
similarity\_threshold & 0.7 \\
welfare\_weight & 0.3 \\
updateless\_commitment & 0.8 \\
decision\_theory & FDT \\
twin\_graph\_min\_edge & 0.3 \\
twin\_graph\_traversal\_depth & 2 \\
twin\_graph\_decay & 0.9 \\
n\_counterfactual\_samples & 20 \\
counterfactual\_noise\_std & 0.1 \\
acausal\_bonus\_weight & 0.1 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Population Composition}

Each run uses a fixed population with approximately 36\% LDT agents (all at the same depth), 27\% honest agents, 18\% opportunistic agents, and 18\% adversarial agents. Exact counts by population size:

\begin{table}[H]
\centering
\begin{tabular}{llllll}
\toprule
\textbf{Population} & \textbf{LDT} & \textbf{Honest} & \textbf{Opportunistic} & \textbf{Adversarial} & \textbf{Total} \\
\midrule
$N=11$ & 4 & 3 & 2 & 2 & 11 \\
$N=25$ & 9 & 7 & 5 & 4 & 25 \\
$N=50$ & 18 & 14 & 9 & 9 & 50 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Simulation Parameters}

\begin{table}[H]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Epochs & 15 \\
Steps per epoch & 10 \\
Payoff: $s_{+}$ & 2.0 \\
Payoff: $s_{-}$ & 1.0 \\
Payoff: $h$ & 1.0 \\
Payoff: $\theta$ & 0.5 \\
Governance: circuit breaker & enabled \\
Governance: reputation decay & 0.05 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Experimental Design}

We sweep acausality depth from 1 to 5 at three population scales:

\begin{table}[H]
\centering
\begin{tabular}{llll}
\toprule
\textbf{Condition} & \textbf{Agents} & \textbf{Seeds} & \textbf{Total Runs} \\
\midrule
Small ($N=11$) & 11 & 20 & 100 \\
Medium ($N=25$) & 25 & 10 & 50 \\
Large ($N=50$) & 50 & 10 & 50 \\
\textbf{Total} & & & \textbf{200} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Metrics}

\begin{itemize}
  \item \textbf{Total Welfare}: cumulative payoff across all agents over all epochs
  \item \textbf{Toxicity Rate}: $E[1-p \mid \text{accepted}]$ --- expected harm from accepted interactions
  \item \textbf{LDT Payoff}: mean total payoff for LDT agents specifically
  \item \textbf{Quality Gap}: $E[p|\text{accepted}] - E[p|\text{rejected}]$ --- selection quality
  \item \textbf{Honest/Opportunistic Payoff}: per-class mean payoffs (cooperation externality measures)
\end{itemize}

\subsection{Reproducibility}

All runs use deterministic seeding. The study script is \texttt{examples/ldt\_depth\_sweep\_study.py}. Raw results are exported as CSV.

\section{Results}

\subsection{Small Population ($N=11$, 20 seeds)}

\begin{table}[H]
\centering
\begin{tabular}{lllllll}
\toprule
\textbf{Depth} & \textbf{Welfare} & \textbf{W Std} & \textbf{Toxicity} & \textbf{LDT Payoff} & \textbf{Honest} & \textbf{Opp} \\
\midrule
1 & 295.2 & 14.7 & 0.324 & 41.8 & 15.2 & 20.6 \\
2 & 287.8 & 14.2 & 0.322 & 40.0 & 15.2 & 20.5 \\
\textbf{3} & \textbf{304.3} & 16.9 & 0.323 & \textbf{44.7} & \textbf{16.4} & 19.0 \\
4 & 300.1 & 16.9 & 0.323 & 40.8 & 16.0 & 22.2 \\
5 & 296.8 & 19.0 & \textbf{0.321} & 39.7 & 16.1 & 22.4 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{welfare_by_depth.png}
\caption{Welfare by acausality depth ($N=11$, 20 seeds).}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{toxicity_by_depth.png}
\caption{Toxicity by acausality depth ($N=11$, 20 seeds).}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{ldt_payoff_by_depth.png}
\caption{LDT payoff by acausality depth ($N=11$, 20 seeds).}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{depth1_vs_5_comparison.png}
\caption{Depth 1 vs 5 comparison ($N=11$).}
\end{figure}

\textbf{Key observations ($N=11$):}
\begin{itemize}
  \item Depth 3 (recursive equilibrium) achieves the highest welfare (304.3, +3.1\% over depth 1) and the highest LDT payoff (44.7, +7.1\% over depth 1).
  \item Depths 4--5 regress toward depth 1 levels. Depth 5 yields the \textit{lowest} LDT payoff (39.7, $-5.0\%$ vs depth 1).
  \item Depth 5 has the highest variance (std 19.0 vs 14.7 for depth 1), consistent with Monte Carlo noise injection.
  \item Toxicity is essentially flat across all depths (0.321--0.324), indicating acausal reasoning depth does not affect ecosystem harm.
  \item Opportunistic agents earn more against deeper LDT agents (20.6 at depth 1 vs 22.4 at depth 5), suggesting deeper reasoning may be marginally more exploitable.
\end{itemize}

\subsection{Medium Population ($N=25$, 10 seeds)}

\begin{table}[H]
\centering
\begin{tabular}{lllllll}
\toprule
\textbf{Depth} & \textbf{Welfare} & \textbf{W Std} & \textbf{Toxicity} & \textbf{LDT Payoff} & \textbf{Honest} & \textbf{Opp} \\
\midrule
1 & 555.5 & 24.2 & 0.298 & 42.2 & 12.1 & 10.1 \\
\textbf{2} & \textbf{574.2} & 16.1 & 0.298 & \textbf{44.0} & \textbf{12.4} & 10.2 \\
3 & 559.4 & 19.3 & 0.299 & 42.7 & 12.2 & 10.0 \\
4 & 562.2 & 23.5 & 0.298 & 43.5 & 12.4 & 9.3 \\
5 & 564.9 & 16.3 & 0.298 & 43.4 & 12.2 & 9.8 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{25agents_welfare_by_depth.png}
\caption{Welfare by acausality depth ($N=25$, 10 seeds).}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{25agents_ldt_payoff_by_depth.png}
\caption{LDT payoff by acausality depth ($N=25$, 10 seeds).}
\end{figure}

\textbf{Key observations ($N=25$):}
\begin{itemize}
  \item The depth advantage narrows substantially. The welfare range compresses to 18.8 points (3.4\% spread vs 5.8\% at $N=11$).
  \item Depth 2 (policy introspection) now leads in welfare (574.2) rather than depth 3.
  \item Toxicity converges to 0.298 across all depths (within 0.001).
  \item Opportunistic payoffs drop dramatically (10.1 vs 20.6 at $N=11$) --- larger cooperative populations suppress exploitation.
\end{itemize}

\subsection{Large Population ($N=50$, 10 seeds)}

\begin{table}[H]
\centering
\begin{tabular}{lllllll}
\toprule
\textbf{Depth} & \textbf{Welfare} & \textbf{W Std} & \textbf{Toxicity} & \textbf{LDT Payoff} & \textbf{Honest} & \textbf{Opp} \\
\midrule
\textbf{1} & \textbf{722.8} & 24.9 & 0.271 & \textbf{39.1} & 1.4 & 0.0 \\
2 & 717.6 & 17.6 & 0.271 & 38.7 & 1.5 & 0.0 \\
\textbf{3} & \textbf{722.8} & 20.0 & 0.271 & \textbf{39.1} & 1.4 & 0.0 \\
4 & 714.4 & 23.9 & 0.272 & 38.5 & 1.5 & 0.0 \\
5 & 712.1 & 24.2 & 0.271 & 38.4 & 1.5 & 0.0 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{50agents_welfare_by_depth.png}
\caption{Welfare by acausality depth ($N=50$, 10 seeds).}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{50agents_ldt_payoff_by_depth.png}
\caption{LDT payoff by acausality depth ($N=50$, 10 seeds).}
\end{figure}

\textbf{Key observations ($N=50$):}
\begin{itemize}
  \item \textbf{Depth is irrelevant at scale.} The welfare range across depths is 10.7 points --- well within 1 standard deviation ($\sim$22 points). Depths 1 and 3 are statistically tied at 722.8.
  \item Toxicity is 0.271 across all depths, indistinguishable to three decimal places.
  \item Opportunistic agents earn 0.0 payoff --- completely crowded out by the cooperative majority.
  \item LDT payoff narrows to a 0.7-point range (38.4--39.1) compared to 5.1 points at $N=11$.
\end{itemize}

\subsection{Cross-Scale Comparison}

\begin{table}[H]
\centering
\begin{tabular}{lllll}
\toprule
\textbf{Metric} & \textbf{$N=11$ best} & \textbf{$N=25$ best} & \textbf{$N=50$ best} \\
\midrule
Welfare & 3 (304.3) & 2 (574.2) & 3 (722.8) \\
LDT Payoff & 3 (44.7) & 2 (44.0) & 3 (39.1) \\
Lowest Toxicity & 5 (0.321) & 5 (0.298) & 1 (0.271) \\
Welfare spread & 16.6 (5.8\%) & 18.8 (3.4\%) & 10.7 (1.5\%) \\
\bottomrule
\end{tabular}
\end{table}

The relative welfare spread shrinks from 5.8\% to 3.4\% to 1.5\% as population grows, confirming convergence.

\subsection{Toxicity by Population Scale}

\begin{table}[H]
\centering
\begin{tabular}{lll}
\toprule
\textbf{$N$} & \textbf{Toxicity (all depths)} & \textbf{Std} \\
\midrule
11 & 0.322 & 0.004 \\
25 & 0.298 & 0.004 \\
50 & 0.271 & 0.003 \\
\bottomrule
\end{tabular}
\end{table}

Toxicity decreases monotonically with population size regardless of acausal reasoning depth, dropping 15.8\% from $N=11$ to $N=50$. Population composition effects dominate individual agent decision quality for ecosystem safety metrics.

\section{Discussion}

\subsection{The Inverted-U of Acausal Depth}

Our results reveal an inverted-U relationship between acausal reasoning depth and cooperation outcomes at small scale: performance improves from depth 1 to depth 3, then declines at depths 4--5. This suggests that the \textbf{optimal reasoning depth is bounded} --- adding more acausal machinery (transitive twin graphs, Monte Carlo sampling) introduces noise and computational overhead without providing actionable information that the simpler recursive equilibrium misses.

The decline at depth 4--5 likely reflects two mechanisms:
\begin{enumerate}
  \item \textbf{Noise injection}: Monte Carlo sampling adds stochastic variation to decisions, which may break cooperation equilibria that the deterministic depth-3 solver maintains.
  \item \textbf{Indirect twin dilution}: The transitive twin graph includes agents connected through weak intermediate links, whose cooperation history may be uninformative or misleading.
\end{enumerate}

\subsection{Scale Eliminates Depth Effects}

The most striking finding is that depth advantages vanish at scale. At $N=50$, the welfare difference between the best and worst depth is 1.5\% --- within noise. This aligns with a \textbf{law of large numbers} interpretation: in larger populations, each agent's individual decision quality matters less because the \textit{aggregate} interaction pattern converges to a population-level statistical regularity.

This has practical implications for multi-agent system design: investing in sophisticated acausal reasoning machinery is only justified for small, tightly-coupled populations where individual decisions have outsized impact on collective outcomes.

\subsection{Exploitation Dynamics}

An unexpected finding is that opportunistic agents earn \textit{more} against deeper-reasoning LDT agents at small scale (22.4 at depth 5 vs 20.6 at depth 1). One explanation is that deeper reasoning makes LDT agents more predictable --- the transitive twin graph and MC sampling may produce more uniform behavior across the LDT population, creating a stable pattern that opportunistic agents can exploit. At larger scales this effect vanishes because opportunistic agents are crowded out (payoff drops to 0.0 at $N=50$).

\subsection{Honest Agent Externalities}

Honest agents benefit from LDT cooperation at all scales, with their payoff peaking when LDT agents use depth 3 at $N=11$ (16.4) and depth 2 at $N=25$ (12.4). The fact that honest agents --- who do not themselves engage in acausal reasoning --- benefit from the LDT agents' cooperation indicates a positive externality of logical decision theory on the broader ecosystem.

\subsection{Connection to Decision Theory Literature}

Our results inform the debate between proponents of increasingly sophisticated decision theories. While UDT and FDT extend TDT with additional reasoning capabilities, our simulations suggest that \textbf{the marginal value of deeper reasoning diminishes rapidly} in multi-agent settings. The recursive equilibrium at depth 3 captures the essential benefit of acausal reasoning (mutual cooperation with logical twins), and further extensions do not improve upon this.

This is consistent with the ``good enough'' principle in bounded rationality (Simon, 1956): agents need not solve the full acausal reasoning problem to achieve near-optimal cooperation. A simple fixed-point computation suffices.

\section{Conclusion}

We extended LDT agents with transitive twin graphs (depth 4) and Monte Carlo counterfactual sampling (depth 5) and tested whether deeper acausal reasoning improves cooperation in multi-agent simulations. Across 200 runs at three population scales, we find that recursive equilibrium (depth 3) is the optimal depth at small scale ($N=11$), achieving +3.1\% welfare and +7.1\% LDT payoff over the baseline. Depths 4--5 regress toward or below baseline performance, with Monte Carlo sampling adding noise without benefit. Most importantly, \textbf{all depth differences vanish at scale} --- at $N=50$, the welfare spread across depths is just 1.5\%, well within noise. Toxicity is invariant to acausal depth at all scales, decreasing only with population size. These findings suggest that the practical value of acausal reasoning is bounded by depth 3 and by population size, and that multi-agent system designers should invest in population composition rather than individual agent sophistication for improving ecosystem-level outcomes.

\section{Limitations}

\begin{itemize}
  \item \textbf{Agent diversity}: All LDT agents within a run share the same acausality depth. Mixed-depth populations may show different dynamics.
  \item \textbf{Adversary sophistication}: We used opportunistic agents as adversaries rather than modeling adversaries that specifically target LDT decision procedures.
  \item \textbf{Parameter sensitivity}: We tested one configuration of twin graph and MC parameters. Different values may shift the optimal depth.
  \item \textbf{Payoff structure}: Our payoff parameters ($s_{+}=2.0$, $s_{-}=1.0$, $h=1.0$) create a moderate-stakes environment. High-stakes environments (large $h$) might make deeper reasoning more valuable.
  \item \textbf{Scale ceiling}: Our largest population is $N=50$. Genuinely large-scale systems ($N > 1000$) might exhibit qualitatively different dynamics.
  \item \textbf{Simulation fidelity}: SWARM agents interact through a structured protocol with soft labels. Real-world multi-agent systems have richer interaction modalities.
\end{itemize}

\section*{References}

\begin{itemize}[leftmargin=*]
  \item Soares, N., \& Fallenstein, B. (2017). Agent Foundations for Aligning Machine Intelligence with Human Interests. \textit{MIRI Technical Report}.
  \item Yudkowsky, E., \& Soares, N. (2018). Functional Decision Theory: A New Theory of Instrumental Rationality. \textit{arXiv:1710.05060}.
  \item Simon, H. A. (1956). Rational Choice and the Structure of the Environment. \textit{Psychological Review, 63}(2), 129--138.
  \item Wei, J., et al. (2024). Functional Decision Theory in Multi-Agent Simulation. \textit{Proceedings of AAMAS 2024}.
\end{itemize}

\end{document}
