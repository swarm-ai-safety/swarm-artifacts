{
  "hawk_dove_adaptive_rho_0.0": {
    "game_type": "hawk_dove",
    "regime": "adaptive",
    "rho_a": 0.0,
    "n_runs": 5,
    "toxicity_mean": 0.23647105854622333,
    "toxicity_std": 0.008463484268561004,
    "welfare_mean": 594.3447857918251,
    "welfare_std": 21.86572807967283,
    "quality_gap_mean": 0.4336322309277779,
    "quality_gap_std": 0.017195011515357607,
    "acceptance_rate_mean": 0.5896,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.5714285714285714,
    "p_break_even_extern": 0.7692307692307693
  },
  "hawk_dove_adaptive_rho_0.2": {
    "game_type": "hawk_dove",
    "regime": "adaptive",
    "rho_a": 0.2,
    "n_runs": 5,
    "toxicity_mean": 0.2243870083935033,
    "toxicity_std": 0.006736052387287711,
    "welfare_mean": 487.602639461218,
    "welfare_std": 21.841579181645915,
    "quality_gap_mean": 0.43279122095288564,
    "quality_gap_std": 0.017460048108031756,
    "acceptance_rate_mean": 0.5606666666666666,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.5714285714285714,
    "p_break_even_extern": 0.7692307692307693
  },
  "hawk_dove_adaptive_rho_0.4": {
    "game_type": "hawk_dove",
    "regime": "adaptive",
    "rho_a": 0.4,
    "n_runs": 5,
    "toxicity_mean": 0.21663683125909122,
    "toxicity_std": 0.0046855515225643594,
    "welfare_mean": 388.95063056287347,
    "welfare_std": 20.732692807416925,
    "quality_gap_mean": 0.42863878344870987,
    "quality_gap_std": 0.018159700656446627,
    "acceptance_rate_mean": 0.5381333333333334,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.5714285714285714,
    "p_break_even_extern": 0.7692307692307693
  },
  "hawk_dove_adaptive_rho_0.6": {
    "game_type": "hawk_dove",
    "regime": "adaptive",
    "rho_a": 0.6,
    "n_runs": 5,
    "toxicity_mean": 0.21047362038165546,
    "toxicity_std": 0.005531194315594787,
    "welfare_mean": 296.23348255515896,
    "welfare_std": 23.3346102796194,
    "quality_gap_mean": 0.41962105989030885,
    "quality_gap_std": 0.017095600388630977,
    "acceptance_rate_mean": 0.5136,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.5714285714285714,
    "p_break_even_extern": 0.7692307692307693
  },
  "hawk_dove_adaptive_rho_0.8": {
    "game_type": "hawk_dove",
    "regime": "adaptive",
    "rho_a": 0.8,
    "n_runs": 5,
    "toxicity_mean": 0.19899927139062357,
    "toxicity_std": 0.004301995705218745,
    "welfare_mean": 216.2984084781855,
    "welfare_std": 22.70962811514848,
    "quality_gap_mean": 0.3865556660021926,
    "quality_gap_std": 0.019470925464153042,
    "acceptance_rate_mean": 0.4418666666666667,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.5714285714285714,
    "p_break_even_extern": 0.7692307692307693
  },
  "hawk_dove_adaptive_rho_1.0": {
    "game_type": "hawk_dove",
    "regime": "adaptive",
    "rho_a": 1.0,
    "n_runs": 5,
    "toxicity_mean": 0.156572038991212,
    "toxicity_std": 0.003734497667189898,
    "welfare_mean": 134.85245523863978,
    "welfare_std": 20.956354438094944,
    "quality_gap_mean": 0.317243661697568,
    "quality_gap_std": 0.014487831191791877,
    "acceptance_rate_mean": 0.186,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.5714285714285714,
    "p_break_even_extern": 0.7692307692307693
  },
  "hawk_dove_adaptive_learning_rho_0.0": {
    "game_type": "hawk_dove",
    "regime": "adaptive_learning",
    "rho_a": 0.0,
    "n_runs": 5,
    "toxicity_mean": 0.27198360408156014,
    "toxicity_std": 0.007983084604341722,
    "welfare_mean": 587.9594725297108,
    "welfare_std": 21.4996095220375,
    "quality_gap_mean": 0.33571684562435916,
    "quality_gap_std": 0.013010140126855243,
    "acceptance_rate_mean": 0.7158666666666667,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.5204583342669165,
    "mean_p_exploitative": 0.3827050054285742,
    "avg_final_tp_selfish": 0.5329550804834748,
    "avg_final_tp_exploitative": 0.18515289787790398,
    "p_break_even_surplus": 0.5714285714285714,
    "p_break_even_extern": 0.7692307692307693
  },
  "hawk_dove_adaptive_learning_rho_0.2": {
    "game_type": "hawk_dove",
    "regime": "adaptive_learning",
    "rho_a": 0.2,
    "n_runs": 5,
    "toxicity_mean": 0.24872608596754003,
    "toxicity_std": 0.004901859056279653,
    "welfare_mean": 479.82384212613283,
    "welfare_std": 19.02720652227872,
    "quality_gap_mean": 0.325731021021694,
    "quality_gap_std": 0.011764120755498533,
    "acceptance_rate_mean": 0.6662666666666667,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.5457490386455318,
    "mean_p_exploitative": 0.3909171396815176,
    "avg_final_tp_selfish": 0.6107271692771586,
    "avg_final_tp_exploitative": 0.16651736470763587,
    "p_break_even_surplus": 0.5714285714285714,
    "p_break_even_extern": 0.7692307692307693
  },
  "hawk_dove_adaptive_learning_rho_0.4": {
    "game_type": "hawk_dove",
    "regime": "adaptive_learning",
    "rho_a": 0.4,
    "n_runs": 5,
    "toxicity_mean": 0.23212472890156577,
    "toxicity_std": 0.004877597001414166,
    "welfare_mean": 387.1429213941748,
    "welfare_std": 23.934769344522067,
    "quality_gap_mean": 0.3083017493630223,
    "quality_gap_std": 0.012146951474197016,
    "acceptance_rate_mean": 0.6310666666666667,
    "mean_p_cooperative": 0.79081593276379,
    "mean_p_selfish": 0.5729772057142412,
    "mean_p_exploitative": 0.4053430835120038,
    "avg_final_tp_selfish": 0.6304002438193778,
    "avg_final_tp_exploitative": 0.19357258151785106,
    "p_break_even_surplus": 0.5714285714285714,
    "p_break_even_extern": 0.7692307692307693
  },
  "hawk_dove_adaptive_learning_rho_0.6": {
    "game_type": "hawk_dove",
    "regime": "adaptive_learning",
    "rho_a": 0.6,
    "n_runs": 5,
    "toxicity_mean": 0.21734638576033743,
    "toxicity_std": 0.005375504139570553,
    "welfare_mean": 303.5490393255105,
    "welfare_std": 26.606292999684335,
    "quality_gap_mean": 0.291159879589382,
    "quality_gap_std": 0.010803236023144732,
    "acceptance_rate_mean": 0.5813333333333334,
    "mean_p_cooperative": 0.7915010743799108,
    "mean_p_selfish": 0.5913753754977552,
    "mean_p_exploitative": 0.4066255394218899,
    "avg_final_tp_selfish": 0.6748225736363503,
    "avg_final_tp_exploitative": 0.19687037222283682,
    "p_break_even_surplus": 0.5714285714285714,
    "p_break_even_extern": 0.7692307692307693
  },
  "hawk_dove_adaptive_learning_rho_0.8": {
    "game_type": "hawk_dove",
    "regime": "adaptive_learning",
    "rho_a": 0.8,
    "n_runs": 5,
    "toxicity_mean": 0.1927666758447863,
    "toxicity_std": 0.0049404570283890885,
    "welfare_mean": 283.3475254294881,
    "welfare_std": 25.66144550112801,
    "quality_gap_mean": 0.27950043387925355,
    "quality_gap_std": 0.01473136420881123,
    "acceptance_rate_mean": 0.5205333333333333,
    "mean_p_cooperative": 0.8068580292797323,
    "mean_p_selfish": 0.6057622492067068,
    "mean_p_exploitative": 0.4070963760280472,
    "avg_final_tp_selfish": 0.6853892033708235,
    "avg_final_tp_exploitative": 0.197242886135719,
    "p_break_even_surplus": 0.5714285714285714,
    "p_break_even_extern": 0.7692307692307693
  },
  "hawk_dove_adaptive_learning_rho_1.0": {
    "game_type": "hawk_dove",
    "regime": "adaptive_learning",
    "rho_a": 1.0,
    "n_runs": 5,
    "toxicity_mean": 0.14651309067033141,
    "toxicity_std": 0.002874447661543609,
    "welfare_mean": 348.88522663813103,
    "welfare_std": 22.357188407650114,
    "quality_gap_mean": 0.2825083403251408,
    "quality_gap_std": 0.017188627533000402,
    "acceptance_rate_mean": 0.4244,
    "mean_p_cooperative": 0.8409659122172619,
    "mean_p_selfish": 0.607834886006745,
    "mean_p_exploitative": 0.4072082074647175,
    "avg_final_tp_selfish": 0.6897401330268396,
    "avg_final_tp_exploitative": 0.19727011138716255,
    "p_break_even_surplus": 0.5714285714285714,
    "p_break_even_extern": 0.7692307692307693
  },
  "prisoners_dilemma_adaptive_rho_0.0": {
    "game_type": "prisoners_dilemma",
    "regime": "adaptive",
    "rho_a": 0.0,
    "n_runs": 5,
    "toxicity_mean": 0.23647105854622333,
    "toxicity_std": 0.008463484268561004,
    "welfare_mean": 1141.1526735358482,
    "welfare_std": 24.1587548021298,
    "quality_gap_mean": 0.4336322309277779,
    "quality_gap_std": 0.017195011515357607,
    "acceptance_rate_mean": 0.5896,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.3333333333333333,
    "p_break_even_extern": 0.6
  },
  "prisoners_dilemma_adaptive_rho_0.2": {
    "game_type": "prisoners_dilemma",
    "regime": "adaptive",
    "rho_a": 0.2,
    "n_runs": 5,
    "toxicity_mean": 0.2243870083935033,
    "toxicity_std": 0.006736052387287711,
    "welfare_mean": 1040.23145711418,
    "welfare_std": 27.768864314535257,
    "quality_gap_mean": 0.43279122095288564,
    "quality_gap_std": 0.017460048108031756,
    "acceptance_rate_mean": 0.5606666666666666,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.3333333333333333,
    "p_break_even_extern": 0.6
  },
  "prisoners_dilemma_adaptive_rho_0.4": {
    "game_type": "prisoners_dilemma",
    "regime": "adaptive",
    "rho_a": 0.4,
    "n_runs": 5,
    "toxicity_mean": 0.21663683125909122,
    "toxicity_std": 0.0046855515225643594,
    "welfare_mean": 949.9260417316834,
    "welfare_std": 28.1010776781588,
    "quality_gap_mean": 0.42863878344870987,
    "quality_gap_std": 0.018159700656446627,
    "acceptance_rate_mean": 0.5381333333333334,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.3333333333333333,
    "p_break_even_extern": 0.6
  },
  "prisoners_dilemma_adaptive_rho_0.6": {
    "game_type": "prisoners_dilemma",
    "regime": "adaptive",
    "rho_a": 0.6,
    "n_runs": 5,
    "toxicity_mean": 0.21047362038165546,
    "toxicity_std": 0.005531194315594787,
    "welfare_mean": 859.7925710814455,
    "welfare_std": 23.29833003544259,
    "quality_gap_mean": 0.41962105989030885,
    "quality_gap_std": 0.017095600388630977,
    "acceptance_rate_mean": 0.5136,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.3333333333333333,
    "p_break_even_extern": 0.6
  },
  "prisoners_dilemma_adaptive_rho_0.8": {
    "game_type": "prisoners_dilemma",
    "regime": "adaptive",
    "rho_a": 0.8,
    "n_runs": 5,
    "toxicity_mean": 0.19899927139062357,
    "toxicity_std": 0.004301995705218745,
    "welfare_mean": 719.1004540677368,
    "welfare_std": 37.871255322922956,
    "quality_gap_mean": 0.3865556660021926,
    "quality_gap_std": 0.019470925464153042,
    "acceptance_rate_mean": 0.4418666666666667,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.3333333333333333,
    "p_break_even_extern": 0.6
  },
  "prisoners_dilemma_adaptive_rho_1.0": {
    "game_type": "prisoners_dilemma",
    "regime": "adaptive",
    "rho_a": 1.0,
    "n_runs": 5,
    "toxicity_mean": 0.156572038991212,
    "toxicity_std": 0.003734497667189898,
    "welfare_mean": 339.8095809527997,
    "welfare_std": 46.859775792066806,
    "quality_gap_mean": 0.317243661697568,
    "quality_gap_std": 0.014487831191791877,
    "acceptance_rate_mean": 0.186,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.3333333333333333,
    "p_break_even_extern": 0.6
  },
  "prisoners_dilemma_adaptive_learning_rho_0.0": {
    "game_type": "prisoners_dilemma",
    "regime": "adaptive_learning",
    "rho_a": 0.0,
    "n_runs": 5,
    "toxicity_mean": 0.27198360408156014,
    "toxicity_std": 0.007983084604341722,
    "welfare_mean": 1270.9652621683224,
    "welfare_std": 28.938238007805378,
    "quality_gap_mean": 0.33571684562435916,
    "quality_gap_std": 0.013010140126855243,
    "acceptance_rate_mean": 0.7158666666666667,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.5204583342669165,
    "mean_p_exploitative": 0.3827050054285742,
    "avg_final_tp_selfish": 0.5329550804834748,
    "avg_final_tp_exploitative": 0.18515289787790398,
    "p_break_even_surplus": 0.3333333333333333,
    "p_break_even_extern": 0.6
  },
  "prisoners_dilemma_adaptive_learning_rho_0.2": {
    "game_type": "prisoners_dilemma",
    "regime": "adaptive_learning",
    "rho_a": 0.2,
    "n_runs": 5,
    "toxicity_mean": 0.24872608596754003,
    "toxicity_std": 0.004901859056279653,
    "welfare_mean": 1153.5466007875243,
    "welfare_std": 24.125544460764264,
    "quality_gap_mean": 0.325731021021694,
    "quality_gap_std": 0.011764120755498533,
    "acceptance_rate_mean": 0.6662666666666667,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.5457490386455318,
    "mean_p_exploitative": 0.3909171396815176,
    "avg_final_tp_selfish": 0.6107271692771586,
    "avg_final_tp_exploitative": 0.16651736470763587,
    "p_break_even_surplus": 0.3333333333333333,
    "p_break_even_extern": 0.6
  },
  "prisoners_dilemma_adaptive_learning_rho_0.4": {
    "game_type": "prisoners_dilemma",
    "regime": "adaptive_learning",
    "rho_a": 0.4,
    "n_runs": 5,
    "toxicity_mean": 0.23212472890156577,
    "toxicity_std": 0.004877597001414166,
    "welfare_mean": 1058.2049151697574,
    "welfare_std": 35.61993113892216,
    "quality_gap_mean": 0.3083017493630223,
    "quality_gap_std": 0.012146951474197016,
    "acceptance_rate_mean": 0.6310666666666667,
    "mean_p_cooperative": 0.79081593276379,
    "mean_p_selfish": 0.5729772057142412,
    "mean_p_exploitative": 0.4053430835120038,
    "avg_final_tp_selfish": 0.6304002438193778,
    "avg_final_tp_exploitative": 0.19357258151785106,
    "p_break_even_surplus": 0.3333333333333333,
    "p_break_even_extern": 0.6
  },
  "prisoners_dilemma_adaptive_learning_rho_0.6": {
    "game_type": "prisoners_dilemma",
    "regime": "adaptive_learning",
    "rho_a": 0.6,
    "n_runs": 5,
    "toxicity_mean": 0.21734638576033743,
    "toxicity_std": 0.005375504139570553,
    "welfare_mean": 948.019993427762,
    "welfare_std": 32.22226752640104,
    "quality_gap_mean": 0.291159879589382,
    "quality_gap_std": 0.010803236023144732,
    "acceptance_rate_mean": 0.5813333333333334,
    "mean_p_cooperative": 0.7915010743799108,
    "mean_p_selfish": 0.5913753754977552,
    "mean_p_exploitative": 0.4066255394218899,
    "avg_final_tp_selfish": 0.6748225736363503,
    "avg_final_tp_exploitative": 0.19687037222283682,
    "p_break_even_surplus": 0.3333333333333333,
    "p_break_even_extern": 0.6
  },
  "prisoners_dilemma_adaptive_learning_rho_0.8": {
    "game_type": "prisoners_dilemma",
    "regime": "adaptive_learning",
    "rho_a": 0.8,
    "n_runs": 5,
    "toxicity_mean": 0.1927666758447863,
    "toxicity_std": 0.0049404570283890885,
    "welfare_mean": 869.3760367755327,
    "welfare_std": 27.490062471409548,
    "quality_gap_mean": 0.27950043387925355,
    "quality_gap_std": 0.01473136420881123,
    "acceptance_rate_mean": 0.5205333333333333,
    "mean_p_cooperative": 0.8068580292797323,
    "mean_p_selfish": 0.6057622492067068,
    "mean_p_exploitative": 0.4070963760280472,
    "avg_final_tp_selfish": 0.6853892033708235,
    "avg_final_tp_exploitative": 0.197242886135719,
    "p_break_even_surplus": 0.3333333333333333,
    "p_break_even_extern": 0.6
  },
  "prisoners_dilemma_adaptive_learning_rho_1.0": {
    "game_type": "prisoners_dilemma",
    "regime": "adaptive_learning",
    "rho_a": 1.0,
    "n_runs": 5,
    "toxicity_mean": 0.14651309067033141,
    "toxicity_std": 0.002874447661543609,
    "welfare_mean": 807.034789721638,
    "welfare_std": 34.96923543649856,
    "quality_gap_mean": 0.2825083403251408,
    "quality_gap_std": 0.017188627533000402,
    "acceptance_rate_mean": 0.4244,
    "mean_p_cooperative": 0.8409659122172619,
    "mean_p_selfish": 0.607834886006745,
    "mean_p_exploitative": 0.4072082074647175,
    "avg_final_tp_selfish": 0.6897401330268396,
    "avg_final_tp_exploitative": 0.19727011138716255,
    "p_break_even_surplus": 0.3333333333333333,
    "p_break_even_extern": 0.6
  },
  "stag_hunt_adaptive_rho_0.0": {
    "game_type": "stag_hunt",
    "regime": "adaptive",
    "rho_a": 0.0,
    "n_runs": 5,
    "toxicity_mean": 0.23647105854622333,
    "toxicity_std": 0.008463484268561004,
    "welfare_mean": 2596.1290103037754,
    "welfare_std": 52.3862914956796,
    "quality_gap_mean": 0.4336322309277779,
    "quality_gap_std": 0.017195011515357607,
    "acceptance_rate_mean": 0.5896,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.1111111111111111,
    "p_break_even_extern": 0.2727272727272727
  },
  "stag_hunt_adaptive_rho_0.2": {
    "game_type": "stag_hunt",
    "regime": "adaptive",
    "rho_a": 0.2,
    "n_runs": 5,
    "toxicity_mean": 0.2243870083935033,
    "toxicity_std": 0.006736052387287711,
    "welfare_mean": 2476.849367187251,
    "welfare_std": 62.89589639514037,
    "quality_gap_mean": 0.43279122095288564,
    "quality_gap_std": 0.017460048108031756,
    "acceptance_rate_mean": 0.5606666666666666,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.1111111111111111,
    "p_break_even_extern": 0.2727272727272727
  },
  "stag_hunt_adaptive_rho_0.4": {
    "game_type": "stag_hunt",
    "regime": "adaptive",
    "rho_a": 0.4,
    "n_runs": 5,
    "toxicity_mean": 0.21663683125909122,
    "toxicity_std": 0.0046855515225643594,
    "welfare_mean": 2371.978316969805,
    "welfare_std": 61.56935777587073,
    "quality_gap_mean": 0.42863878344870987,
    "quality_gap_std": 0.018159700656446627,
    "acceptance_rate_mean": 0.5381333333333334,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.1111111111111111,
    "p_break_even_extern": 0.2727272727272727
  },
  "stag_hunt_adaptive_rho_0.6": {
    "game_type": "stag_hunt",
    "regime": "adaptive",
    "rho_a": 0.6,
    "n_runs": 5,
    "toxicity_mean": 0.21047362038165546,
    "toxicity_std": 0.005531194315594787,
    "welfare_mean": 2254.6624077417587,
    "welfare_std": 43.227406156574176,
    "quality_gap_mean": 0.41962105989030885,
    "quality_gap_std": 0.017095600388630977,
    "acceptance_rate_mean": 0.5136,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.1111111111111111,
    "p_break_even_extern": 0.2727272727272727
  },
  "stag_hunt_adaptive_rho_0.8": {
    "game_type": "stag_hunt",
    "regime": "adaptive",
    "rho_a": 0.8,
    "n_runs": 5,
    "toxicity_mean": 0.19899927139062357,
    "toxicity_std": 0.004301995705218745,
    "welfare_mean": 1952.4070449041346,
    "welfare_std": 88.4316396688,
    "quality_gap_mean": 0.3865556660021926,
    "quality_gap_std": 0.019470925464153042,
    "acceptance_rate_mean": 0.4418666666666667,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.1111111111111111,
    "p_break_even_extern": 0.2727272727272727
  },
  "stag_hunt_adaptive_rho_1.0": {
    "game_type": "stag_hunt",
    "regime": "adaptive",
    "rho_a": 1.0,
    "n_runs": 5,
    "toxicity_mean": 0.156572038991212,
    "toxicity_std": 0.003734497667189898,
    "welfare_mean": 875.9905390480797,
    "welfare_std": 117.74844848204334,
    "quality_gap_mean": 0.317243661697568,
    "quality_gap_std": 0.014487831191791877,
    "acceptance_rate_mean": 0.186,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.40786634347600204,
    "mean_p_exploitative": 0.32452886155685834,
    "avg_final_tp_selfish": 0.2635274128398764,
    "avg_final_tp_exploitative": 0.13517998145717844,
    "p_break_even_surplus": 0.1111111111111111,
    "p_break_even_extern": 0.2727272727272727
  },
  "stag_hunt_adaptive_learning_rho_0.0": {
    "game_type": "stag_hunt",
    "regime": "adaptive_learning",
    "rho_a": 0.0,
    "n_runs": 5,
    "toxicity_mean": 0.27198360408156014,
    "toxicity_std": 0.007983084604341722,
    "welfare_mean": 2980.247893252483,
    "welfare_std": 73.57772337055759,
    "quality_gap_mean": 0.33571684562435916,
    "quality_gap_std": 0.013010140126855243,
    "acceptance_rate_mean": 0.7158666666666667,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.5204583342669165,
    "mean_p_exploitative": 0.3827050054285742,
    "avg_final_tp_selfish": 0.5329550804834748,
    "avg_final_tp_exploitative": 0.18515289787790398,
    "p_break_even_surplus": 0.1111111111111111,
    "p_break_even_extern": 0.2727272727272727
  },
  "stag_hunt_adaptive_learning_rho_0.2": {
    "game_type": "stag_hunt",
    "regime": "adaptive_learning",
    "rho_a": 0.2,
    "n_runs": 5,
    "toxicity_mean": 0.24872608596754003,
    "toxicity_std": 0.004901859056279653,
    "welfare_mean": 2829.161477559226,
    "welfare_std": 55.44213169622729,
    "quality_gap_mean": 0.325731021021694,
    "quality_gap_std": 0.011764120755498533,
    "acceptance_rate_mean": 0.6662666666666667,
    "mean_p_cooperative": 0.7908015671145716,
    "mean_p_selfish": 0.5457490386455318,
    "mean_p_exploitative": 0.3909171396815176,
    "avg_final_tp_selfish": 0.6107271692771586,
    "avg_final_tp_exploitative": 0.16651736470763587,
    "p_break_even_surplus": 0.1111111111111111,
    "p_break_even_extern": 0.2727272727272727
  },
  "stag_hunt_adaptive_learning_rho_0.4": {
    "game_type": "stag_hunt",
    "regime": "adaptive_learning",
    "rho_a": 0.4,
    "n_runs": 5,
    "toxicity_mean": 0.23212472890156577,
    "toxicity_std": 0.004877597001414166,
    "welfare_mean": 2709.6958116662668,
    "welfare_std": 83.71730825870043,
    "quality_gap_mean": 0.3083017493630223,
    "quality_gap_std": 0.012146951474197016,
    "acceptance_rate_mean": 0.6310666666666667,
    "mean_p_cooperative": 0.79081593276379,
    "mean_p_selfish": 0.5729772057142412,
    "mean_p_exploitative": 0.4053430835120038,
    "avg_final_tp_selfish": 0.6304002438193778,
    "avg_final_tp_exploitative": 0.19357258151785106,
    "p_break_even_surplus": 0.1111111111111111,
    "p_break_even_extern": 0.2727272727272727
  },
  "stag_hunt_adaptive_learning_rho_0.6": {
    "game_type": "stag_hunt",
    "regime": "adaptive_learning",
    "rho_a": 0.6,
    "n_runs": 5,
    "toxicity_mean": 0.21734638576033743,
    "toxicity_std": 0.005375504139570553,
    "welfare_mean": 2521.4528491622837,
    "welfare_std": 70.18580687931808,
    "quality_gap_mean": 0.291159879589382,
    "quality_gap_std": 0.010803236023144732,
    "acceptance_rate_mean": 0.5813333333333334,
    "mean_p_cooperative": 0.7915010743799108,
    "mean_p_selfish": 0.5913753754977552,
    "mean_p_exploitative": 0.4066255394218899,
    "avg_final_tp_selfish": 0.6748225736363503,
    "avg_final_tp_exploitative": 0.19687037222283682,
    "p_break_even_surplus": 0.1111111111111111,
    "p_break_even_extern": 0.2727272727272727
  },
  "stag_hunt_adaptive_learning_rho_0.8": {
    "game_type": "stag_hunt",
    "regime": "adaptive_learning",
    "rho_a": 0.8,
    "n_runs": 5,
    "toxicity_mean": 0.1927666758447863,
    "toxicity_std": 0.0049404570283890885,
    "welfare_mean": 2325.637607589202,
    "welfare_std": 48.83039957041782,
    "quality_gap_mean": 0.27950043387925355,
    "quality_gap_std": 0.01473136420881123,
    "acceptance_rate_mean": 0.5205333333333333,
    "mean_p_cooperative": 0.8068580292797323,
    "mean_p_selfish": 0.6057622492067068,
    "mean_p_exploitative": 0.4070963760280472,
    "avg_final_tp_selfish": 0.6853892033708235,
    "avg_final_tp_exploitative": 0.197242886135719,
    "p_break_even_surplus": 0.1111111111111111,
    "p_break_even_extern": 0.2727272727272727
  },
  "stag_hunt_adaptive_learning_rho_1.0": {
    "game_type": "stag_hunt",
    "regime": "adaptive_learning",
    "rho_a": 1.0,
    "n_runs": 5,
    "toxicity_mean": 0.14651309067033141,
    "toxicity_std": 0.002874447661543609,
    "welfare_mean": 2033.6182686938055,
    "welfare_std": 77.23754021187378,
    "quality_gap_mean": 0.2825083403251408,
    "quality_gap_std": 0.017188627533000402,
    "acceptance_rate_mean": 0.4244,
    "mean_p_cooperative": 0.8409659122172619,
    "mean_p_selfish": 0.607834886006745,
    "mean_p_exploitative": 0.4072082074647175,
    "avg_final_tp_selfish": 0.6897401330268396,
    "avg_final_tp_exploitative": 0.19727011138716255,
    "p_break_even_surplus": 0.1111111111111111,
    "p_break_even_extern": 0.2727272727272727
  }
}